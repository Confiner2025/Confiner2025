<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Training-free Long Video Generation with Chain of Diffusion Model Experts</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f9f9f9;
            color: #333;
        }

        header {
            text-align: center;
            margin-bottom: 40px;
        }

        .artistic-title {
            font-family: 'Georgia', serif;
            font-size: 2.5em;
            color: #333;
            text-shadow: 1px 1px #ddd;
            margin: 0;
        }

        .github-button {
            display: inline-flex;
            align-items: center;
            background-color: #24292e;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 30px;
            font-size: 1em;
            margin-top: 10px;
            cursor: not-allowed;
        }

        .github-button img {
            width: 20px;
            margin-right: 10px;
        }

        section {
            background: #fff;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 0 15px rgba(0, 0, 0, 0.1);
        }

        h2 {
            color: #000;
            border-bottom: none;
            padding-bottom: 10px;
            text-align: center;
            font-size: 1.75em;
        }

        .abstract {
            max-width: 800px;
            margin: 0 auto;
            text-align: justify;
        }

        .video-container {
            display: flex;
            justify-content: space-between;
            flex-wrap: wrap;
            gap: 20px;
            margin: 20px 0;
        }

        .video-container video {
            flex: 1 1 calc(33% - 20px);
            max-width: 100%;
            max-width: 420px;
            border: 1px solid #ddd;
            border-radius: 8px;
        }

        .results img {
            max-width: 100%;
            border: 1px solid #ddd;
            border-radius: 8px;
        }

        p {
            line-height: 1.6;
        }

        .artistic-text {
            font-family: 'Georgia', serif;
            font-style: italic;
            text-align: center;
            margin-top: 10px;
        }

        .pipeline img {
            width: 100%;
            height: auto;
        }

        /* Alternating background colors for sections */
        section:nth-of-type(2n) {
            background-color: #f0f0f0;
        }

        section:nth-of-type(2n+1) {
            background-color: #ffffff;
        }
    </style>
</head>

<body>
    <header>
        <h1 class="artistic-title">Training-free High-quality Video Generation with Chain of Diffusion Model Experts</h1>
        <button class="github-button">
            <img src="path/to/github-icon.png" alt="GitHub logo">Code (coming soon)
        </button>
    </header>

    <section>
        <h2>Abstract</h2>
        <div class="abstract">
            <p>
                Video generation models hold substantial potential in areas such as filmmaking. However, current video diffusion models need high computational costs and produce suboptimal results due to high complexity of video generation task. In this paper, we propose <strong>ConFiner</strong>, an efficient high-quality video generation framework that decouples video generation into easier subtasks: structure <strong>con</strong>trol and spatial-temporal re<strong>fine</strong>ment. It can generate high-quality videos with chain of off-the-shelf diffusion model experts, each expert responsible for a decoupled subtask. During the refinement, we introduce coordinated denoising, which can merge multiple diffusion experts' capabilities into a single sampling. Furthermore, we design ConFiner-Long framework, which can generate long coherent video with three constraint strategies on Confiner. Experimental results indicate that with only 10% of the inference cost, our ConFiner surpasses representative models like Lavie and Modelscope across all objective and subjective metrics. And ConFiner-Long can generate high-quality and coherent videos with up to 600 frames.
            </p>
        </div>
    </section>

    <section>
        <h2>Pipeline</h2>
        <div class="pipeline">
            <img src="main_fig-3.pdf" alt="Pipeline">
        </div>
    </section>

    <section>
        <h2>Example Videos</h2>
        <div class="video-container">
            <div>
                <video controls>
                    <source src="mecha.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p class="artistic-text">Mecha Animation</p>
            </div>
            <div>
                <video controls>
                    <source src="clownfish.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p class="artistic-text">Clownfish in the Sea</p>
            </div>
            <div>
                <video controls>
                    <source src="car.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p class="artistic-text">Speeding Car</p>
            </div>
            <!-- Add remaining videos and captions as needed -->
        </div>
    </section>

    <section>
        <h2>Experimental Results</h2>
        <div class="results">
            <img src="experiments.jpg" alt="Experimental Results">
        </div>
    </section>
</body>

</html>
